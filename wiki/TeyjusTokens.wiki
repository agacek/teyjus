#summary Tokens in Teyjus
= Characterization of Tokens in Teyjus =

We describe below the rules for recognizing tokens in the different relevant categories. Two points are relevant to mention prior to this description. First, as is standard, the principle of longest match is used in tokenization. The Teyjus lexical analyzer is in fact automatically generated by the _OCaml_ equivalent of _flex_, based on a regular grammar presentation of the tokens and token categories below. Second, a far fewer set of characters are treated as token separators than is usual. In particular, only the characters identified as punctuation symbols are interpreted in this manner over and above `white space' characters. To take a specific example, a sequence such as _X+Y_ is interpreted as a token as opposed to a sequence of three tokens.


== Keywords ==

The following sequences of characters are recognized as tokens with a special meaning within Teyjus.
 	
{{{
module     end          import     accumulate     accum_sig   
local      localkind    closed     sig            use_sig
kind       type         exportdef  useonly        infixl 
infixr     infix        prefix     prefixr        postfix 
postfixl   :-           \          ->             !
}}}