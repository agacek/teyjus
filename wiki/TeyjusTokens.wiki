#summary Tokens in Teyjus
= Characterization of Tokens in Teyjus =

We describe below the rules for recognizing tokens in the different relevant categories. Two points are relevant to mention prior to this description. First, as is standard, the principle of longest match is used in tokenization. The Teyjus lexical analyzer is in fact automatically generated by the _OCaml_ equivalent of _flex_, based on a regular grammar presentation of the tokens and token categories below. Second, a far fewer set of characters are treated as token separators than is usual. In particular, only the characters identified as punctuation symbols are interpreted in this manner over and above 'white space' characters. To take a specific example, a sequence such as _X+Y_ is interpreted as a token as opposed to a sequence of three tokens.


== Keywords ==

The following sequences of characters are recognized as tokens with a special meaning within Teyjus.
 	
{{{
module     end          import     accumulate     accum_sig     local
type       closed       sig        use_sig        exportdef     infix         
kind       useonly      infixl     typeabbrev     infixr        prefix      
prefixr    postfix    localkind    postfixl       :-            \          
->         !
}}}

== Other Special Tokens in Teyjus ==

The following tokens are ones that, in addition to the keywords and punctuation symbols, cannot be redefined by user programs. Some of these symbols---in particular, the symbols _pi_, _sigma_, _;_, _&_, _=>_, _=_, _::_ and _nil_---are constants and are like other identifiers except for the 'no redefinition' clause. The remaining symbols are overloaded and so are treated in a special way by the parser. Finally, some symbols, in particular _::_ and _nil_, receive a special treatment at the abstract machine level.
 	
{{{
pi         sigma        ,          ;              &
=>         +            -          *              /
~          <            >          =<             >=
::         =            nil
}}}